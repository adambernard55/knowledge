---
title: "SEO Fundamentals: Core Concepts of Search"
summary: An index of the core principles of SEO, from how search engines work to modern concepts like E-E-A-T and AI's role in search.
seo_category: fundamentals
difficulty: beginner
last_updated: 2025-01-24
kb_status: published
tags:
  - index
  - fundamentals
  - seo-basics
  - overview
---
# AI Fundamentals

This section introduces the foundational principles of Artificial Intelligence. These documents cover the essential "what" and "why" behind AI, explaining how llm models operate, how they evaluate content, and the core concepts that every practitioner must understand to build an effective strategy.

---

## Contents

- **[[00_what-is-ai|What Is Artificial Intelligence (AI)?]]** — This document provides a foundational definition of Artificial Intelligence (AI) as the simulation of human cognitive functions in machines. It details key subfields like Machine Learning (ML), Deep Learning (DL), Natural Language Processing (NLP), and Generative AI. The note explains the AI stack, from data infrastructure to user applications, and outlines AI's strategic business impact on efficiency, personalization, and insight generation. It emphasizes a collaborative model where AI augments human expertise, framing the human role as a strategic "Fleet Commander" rather than a simple operator, while also addressing critical ethical considerations like bias and transparency.
- **[[01_history-of-ai|The History of Artificial Intelligence: From Concept to Reality]]** — This document provides a comprehensive history of Artificial Intelligence, tracing its evolution from ancient philosophical concepts to the current era of agentic ecosystems. It details key periods, including the birth of AI at the Dartmouth Conference, the 'AI Winters', the rise of machine learning, the deep learning revolution of the 2010s, and the generative AI boom of the early 2020s. The note has been updated to reflect 2025-2026 trends, including the development of reasoning-enhanced foundation models (e.g., OpenAI's o-series), the shift to multi-agent systems, the emergence of on-device AI, and a detailed timeline of global AI regulations like the EU AI Act, US federal orders, and state-level legislation.
- **[[02_types-of-ai|Types of Artificial Intelligence: From Narrow AI to Agentic Systems]]** — This document outlines the primary classifications of Artificial Intelligence (AI). It details the capability spectrum from Artificial Narrow Intelligence (ANI), which excels at specific tasks, to the theoretical concepts of Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI). A key update for 2026 is the introduction of "Agentic AI" as a functional type—systems that can plan, use tools, and execute multi-step workflows. The note clarifies that the current state-of-the-art consists of advanced, multi-modal ANI wrapped in agentic runtimes, not true AGI, and provides updated expert timelines and governance context for future AI development.
- **[[03_machine-learning-vs-deep-learning|Machine Learning vs. Deep Learning: Unpacking the Differences]]** — This document clarifies the relationship and distinctions between Machine Learning (ML) and Deep Learning (DL). It explains that DL is a subset of ML using multi-layered neural networks. The note has been updated for 2026 to reflect the impact of foundation models, which are large, pre-trained DL models that can be adapted with smaller datasets. It also covers the rise of TinyML for on-device AI and emerging paradigms like self-supervised learning and hybrid neuro-symbolic approaches. The core comparison is updated to show that modern systems often use DL for representation and classic ML for structured decision-making.
- **[[04_the-ai-stack|The AI Stack: How Modern AI Systems Are Built (2026)]]** — This document provides a 2026 perspective on the AI Stack, detailing its evolution from a model-centric to a system-centric architecture. It outlines five distinct layers: Infrastructure (optimized for inference), Data & Development (vector stores, MLOps), Foundation Models (adapted via RAG/fine-tuning), Serving & Orchestration (tool-calling runtimes, agent frameworks), and Application & Agents (copilots, multi-agent systems). The note emphasizes key industry shifts, including the economic primacy of continuous inference over training and the emergence of a dedicated agentic stack to manage complex, multi-step workflows.
- **[[05_generative-ai-overview|Generative AI: From Content Creation to Agentic Systems (2026)]]** — This document provides a 2026 overview of Generative AI, tracing its evolution from a content creation tool to the engine of autonomous agentic systems. It details key modern architectures, including transformers, diffusion models, and Mixture-of-Experts (MoEs), and explains how Retrieval-Augmented Generation (RAG) and tool-calling enable multi-step reasoning. The note covers expanded applications in enterprise simulation, gaming, and on-device generation, while also addressing contemporary challenges like deepfake detection, computational sustainability, and data provenance.
- **[[06_natural-language-processing|Understanding Natural Language Processing (NLP)]]** — This document explains Natural Language Processing (NLP) as the field of AI that bridges the gap between human language and computer understanding. It details the core pipeline from tokenization to semantic analysis and covers key applications like machine translation, sentiment analysis, and chatbots. The note traces NLP's evolution from statistical methods to the current era dominated by Transformer-based Large Language Models (LLMs), highlighting its critical role as the cognitive engine for modern agentic AI systems.
- **[[07_embeddings-and-vector-databases|Embeddings & Vector Databases: The Foundation of AI Memory]]** — This document explains the concept of embeddings, which are numerical vector representations that capture the semantic meaning of complex data like text and images. It details how these embeddings are stored and queried in specialized vector databases to perform similarity searches. The note highlights their critical applications in powering Retrieval-Augmented Generation (RAG), providing long-term memory for AI agents, and enabling advanced recommendation and search systems.
- **[[08_the-transformer-architecture|The Transformer Architecture: The Engine of Modern AI]]** — This document provides a foundational explanation of the Transformer architecture, the deep learning model that underpins modern AI. It details the limitations of previous sequential models like RNNs and introduces the Transformer's core innovation: the self-attention mechanism. The note explains how self-attention allows for parallel processing and a sophisticated understanding of context, which directly enabled the creation of scalable Large Language Models (LLMs) and the current generative AI boom.
